\chapter{Unsupervised Anomaly Detection and One‑Class Methods}

\section{Learning objectives}

After completing this chapter you will be able to:
\begin{itemize}
  \item Extract features from signal segments for use in unsupervised anomaly detection.
  \item Train and evaluate principal component analysis (PCA)–based detectors and Isolation Forest models on healthy data.
  \item Select thresholds to meet false‑alarm budgets and interpret false‑alarm and detection rates.
  \item Diagnose failure modes such as training on mixed data and inadequate feature sets.
\end{itemize}

\section{Industrial context}

In many applications, faults are rare or diverse, making supervised labelling impractical.  Unsupervised approaches learn the distribution of healthy data and flag deviations as anomalies.  Examples include monitoring acoustic emissions in bearings, network intrusion detection and power quality monitoring.  Care must be taken to avoid training on data that contain anomalies.

\section{Core concepts}

\subsection{Feature extraction}

To detect anomalies in sensor streams, we extract summary statistics from each segment: root‑mean‑square, kurtosis, bandpower and a simple regime indicator (e.g., even/odd segment).  Features should capture both amplitude and spectral characteristics and, if possible, the operating regime to avoid confounding.

\subsection{Principal component analysis}

PCA reduces dimensionality by projecting data onto principal directions of maximum variance.  The reconstruction error—distance between the original data and its projection—serves as an anomaly score.  A threshold is selected so that a fixed percentage (e.g., 5\%) of healthy samples exceed it.

\subsection{Isolation Forest}

Isolation Forest is an ensemble of isolation trees that recursively partition the feature space.  Anomalies require fewer splits to isolate and thus have shorter average path lengths.  Scores are computed as negative path lengths and compared to a threshold determined from healthy samples.  The contamination parameter specifies the expected fraction of anomalies.

\section{Operational formulas}

\paragraph{PCA reconstruction error.}  Given centred feature matrix $\mathbf{X}$ and PCA components $\mathbf{W}$, the reconstruction is $\hat{\mathbf{X}} = \mathbf{X} \mathbf{W} \mathbf{W}^T$.  The error for sample $i$ is $e_i = \|\mathbf{x}_i - \hat{\mathbf{x}}_i\|^2$.  Scores above the chosen percentile threshold are labelled as anomalies.

\paragraph{Isolation Forest scoring.}  For each sample, the anomaly score is the average path length of the sample through the trees.  Scores are normalised such that higher values indicate greater abnormality.  A threshold is again chosen based on the distribution of healthy scores.

\paragraph{Performance metrics.}  Define true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).  Precision, recall and F1‑score are computed from these counts.  False‑alarm rate is FP divided by the number of healthy samples.

\section{Parameter tuning playbook}

\begin{table}[h]
  \centering
  \begin{tabular}{@{}llll@{}}
    \toprule
    \textbf{Knob} & \textbf{Default} & \textbf{Symptom} & \textbf{Adjustment} \\
    \midrule
    Number of PCA components & 2 & Low detection rate & Increase number of components \\
    Contamination (Isolation Forest) & 0.05 & High false‑alarm rate & Decrease contamination or adjust threshold percentile \\
    Feature scaling & Z‑score & Scores dominated by a single feature & Use robust scaling or normalisation \\
    Training data & Healthy only & High miss rate & Ensure training set is free of anomalies and representative of all regimes \\
    \bottomrule
  \end{tabular}
  \caption{Parameter tuning guidelines for unsupervised anomaly detection.}
\end{table}

\section{Pitfalls, failure modes and diagnostics}

\begin{itemize}
  \item \textbf{Contaminated training data.}  Including anomalies in the training set causes the model to treat them as normal, reducing recall.  Always verify training data quality.
  \item \textbf{Inadequate features.}  If features do not capture the anomaly characteristics, both detectors perform poorly.  Enrich the feature set with additional metrics (e.g., spectral skewness, time–frequency coefficients).
  \item \textbf{Threshold selection.}  The false‑alarm rate depends on the threshold percentile.  Tune this parameter using a validation set and consider business constraints.
\end{itemize}

\section{Code walkthrough}

The Week\,13 demonstration extracts features (RMS, kurtosis, bandpower and regime index) from synthetic segments.  It standardises the features, trains PCA and Isolation Forest models on healthy data, and computes reconstruction error and isolation scores on mixed data.  Thresholds are set at the 95th percentile of healthy scores to achieve a 5\% false‑alarm budget.  The checks compute false‑alarm rates and compare performance when training on mixed data to illustrate performance degradation.

\section{Exercises}

\begin{enumerate}
  \item Extend the feature set with spectral skewness and kurtosis.  Evaluate whether the anomaly detectors improve in recall and false‑alarm rate.
  \item Compare the PCA‑based detector with One‑Class SVM.  Discuss computational complexity and detection performance.
  \item Investigate the impact of contamination parameter on Isolation Forest.  Train models with contamination values 0.01, 0.05 and 0.2 and plot false‑alarm and detection rates.
\end{enumerate}

\section{References}

\begin{itemize}
  \item Definitions of cross‑correlation and coherence 【202129906864961†L272-L287】【296435890113586†L67-L72】 provide context for related unsupervised metrics.
\end{itemize}
